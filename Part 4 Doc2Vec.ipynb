{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continued from Part 3 Word2Vec\n",
    "\n",
    "This time we turn each review into a vector representation using Doc2Vec algoritm (https://radimrehurek.com/gensim/models/doc2vec.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models.doc2vec import Doc2Vec, LabeledSentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load the processed data from Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"labeledTrainData.tsv\",\n",
    "                    delimiter=\"\\t\",\n",
    "                    header=0,\n",
    "                    quoting=3)\n",
    "\n",
    "unlabeled = pd.read_csv(\"unlabeledTrainData.tsv\",\n",
    "                        delimiter=\"\\t\",\n",
    "                        header=0,\n",
    "                        quoting=3)\n",
    "\n",
    "train_sents = pickle.load(open(\"train_sents.pickle\"))\n",
    "unlabeled_sents = pickle.load(open(\"unlabeled_sents.pickle\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corpus on which Doc2Vec model is trained on must be an iterable of **LabeledSentence** object (i.e. a list of words, and a unique sentence ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class IMDBReview(object):\n",
    "    def __init__(self, sents, prefix=\"TRAIN\"):\n",
    "        self.sents = sents\n",
    "        self.prefix = prefix\n",
    "    def __iter__(self):\n",
    "        for index, sent in enumerate(self.sents):\n",
    "            yield LabeledSentence(sent.split(), [\"%s_%d\" % (self.prefix, index)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model and build the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Doc2Vec(min_count=1, window=10, size=100, sample=1e-4, negative=5, workers=8)\n",
    "model.build_vocab(IMDBReview(train_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Doc2Vec is unsupervised, so it can be trained using **unlabeled** review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    print epoch\n",
    "    corpus = IMDBReview(train_sents)\n",
    "    model.train(corpus)\n",
    "    corpus = IMDBReview(unlabeled_sents, prefix=\"UNLABELED\")\n",
    "    model.train(corpus)\n",
    "\n",
    "X = np.array([model.docvecs[\"TRAIN_%d\" % i] for i in range(len(train_sents))])\n",
    "y = train[\"sentiment\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***train_sents*** is now turned into a real-valued matrix ***X***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 100)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.51470816, -0.14695954, -0.38569   , ...,  0.54711825,\n",
       "        -0.38615489, -0.6846233 ],\n",
       "       [ 0.58430964,  0.22183745, -1.08024156, ..., -0.14015758,\n",
       "        -1.03678322, -0.08200566],\n",
       "       [ 2.27951765, -0.63483417, -1.43968844, ...,  1.99514902,\n",
       "        -1.36144769, -2.15728498],\n",
       "       ..., \n",
       "       [ 0.61271161,  1.44076931, -0.78728318, ...,  0.67236358,\n",
       "         0.55372548,  0.20077997],\n",
       "       [-0.0238454 ,  0.18018231, -0.45349646, ..., -0.7789551 ,\n",
       "         0.11597048,  0.1945295 ],\n",
       "       [ 0.44540593,  0.58089393, -0.95667773, ...,  0.57978415,\n",
       "         0.46543002,  0.42108217]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try out the quality of vector representation using a simple linear model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86173333333333335"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "lr = LogisticRegression()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "lr.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Doc2Vec(dm/m,d100,n5,w10,s0.0001,t8)'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Doc2Vec(dm=1, dbow_words=1, min_count=1, window=10, size=100, sample=1e-4, negative=5, workers=8)\n",
    "model.build_vocab(IMDBReview(train_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    print epoch\n",
    "    corpus = IMDBReview(train_sents)\n",
    "    model.train(corpus)\n",
    "    corpus = IMDBReview(unlabeled_sents, prefix=\"UNLABELED\")\n",
    "    model.train(corpus)\n",
    "\n",
    "X = np.array([model.docvecs[\"TRAIN_%d\" % i] for i in range(len(train_sents))])\n",
    "y = train[\"sentiment\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86160000000000003"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "lr = LogisticRegression()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "lr.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
